name: Update Conference Data

on:
  schedule:
    # Run daily at 6 AM UTC (1 AM EST / 10 PM PST)
    - cron: '0 6 * * *'
  workflow_dispatch:  # Allow manual triggers

permissions:
  contents: write
  issues: write

jobs:
  update-conferences:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'scripts/scraper/requirements.txt'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/scraper/requirements.txt

      - name: Run conference scraper
        id: scraper
        run: |
          cd scripts/scraper
          python scrape_conferences.py
        continue-on-error: true

      - name: Check for changes
        id: check_changes
        run: |
          git diff --quiet _data/conferences.yml || echo "changes=true" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add _data/conferences.yml
          git commit -m "chore: update conference data [automated]

          Updated conference deadlines and dates from automated scraper."
          git push

      - name: Create issue on failure
        if: steps.scraper.outcome == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            const title = 'Conference Scraper Failed';
            const body = `The automated conference scraper failed on ${new Date().toISOString()}.

            Please check the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.

            ## Common Issues
            - Conference website structure may have changed
            - Network timeout or rate limiting
            - Missing dependencies

            ## Resolution Steps
            1. Check the workflow logs for specific errors
            2. Update the affected scraper in \`scripts/scraper/sources/\`
            3. Alternatively, add manual entries to \`_data/manual_conferences.yml\`

            ## Manual Update
            You can also manually trigger the scraper via the Actions tab using "workflow_dispatch".`;

            // Check if similar issue already exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'scraper-failure'
            });

            const existingIssue = issues.data.find(issue =>
              issue.title === title &&
              new Date(issue.created_at) > new Date(Date.now() - 7 * 24 * 60 * 60 * 1000)
            );

            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['automated', 'scraper-failure']
              });
            }
